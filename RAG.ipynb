{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "iMA8HNdiUr_q",
        "dRkT9BS7UhdO",
        "1sgXPbBf7slN",
        "WMeVOm0Q78HK",
        "rnPMDuAY8O6W"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **RAG Implementation**"
      ],
      "metadata": {
        "id": "Jv1_eJ3q0Y-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic RAG implementation using Gemini API, a sentence transformer and FAISS (manual processing with cosine similarity also available for small datasets). Youtube videos, Wikipedia pages, PDF and TXT supported."
      ],
      "metadata": {
        "id": "3lgf3H7nht_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Write the page titles and video titles you want to feed your RAG with, you can also let empty lists []\n",
        "wikipedia_page_titles = [\"World War I\", \"World War II\"]\n",
        "youtube_video_titles = [\"Cold War\", \"World War\"]\n",
        "\n",
        "#Drag and drop your files and write the path to the folder containing the documents\n",
        "path = '/content'\n",
        "\n",
        "MODE = \"FAISS\" #\"FAISS\" or \"manual\"\n",
        "\n",
        "from google.colab import userdata\n",
        "#Write your API key and choose your AI model\n",
        "API_KEY = userdata.get('GRO_API_KEY')   #'GEM_API_KEY'\n",
        "ai_type = \"groq\"  #\"gemini\", \"groq\", \"mistral\"\n",
        "ai_model = \"llama-3.3-70b-versatile\" # ex : \"gemini-2.0-flash-lite\" \"mistral-small-latest\"\n",
        "\n",
        "YT_API_KEY = userdata.get('YT_API_KEY')"
      ],
      "metadata": {
        "id": "73sLi0YnicZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "sARlqScF0p-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF\n",
        "!pip install wikipedia\n",
        "!pip install faiss-cpu\n",
        "#!pip install faiss-gpu\n",
        "!pip install mistralai\n",
        "!pip install groq\n",
        "!pip install youtube-transcript-api\n",
        "!pip install --upgrade google-api-python-client\n",
        "\n",
        "import numpy as np\n",
        "import re\n",
        "import fitz\n",
        "import wikipedia\n",
        "import faiss\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "#LLM import\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from mistralai import Mistral\n",
        "from groq import Groq\n",
        "\n",
        "#Youtube transcripts\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from googleapiclient.discovery import build"
      ],
      "metadata": {
        "id": "pX8xgkHd8J7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "#model = SentenceTransformer(\"intfloat/multilingual-e5-small\")    #pour celui-ci, créer des embeddings sous forme [query : , passage : ]\n",
        "#model = SentenceTransformer(\"google/embeddinggemma-300m\")"
      ],
      "metadata": {
        "id": "pHhW5Wc60ukZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "5S1d02_U1DiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text: str) -> str:\n",
        "    text = re.sub(r\"http[s]?://\\S+\", \"\", text)\n",
        "    text = re.sub(r\"\\s*\\n\\s*\", \" \", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "    return text.strip()"
      ],
      "metadata": {
        "id": "mAK-gfbEY5ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "folder = Path(path)"
      ],
      "metadata": {
        "id": "EO9YPgpgIatN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TXT files"
      ],
      "metadata": {
        "id": "tzQ1CiT8RQWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for file in folder.glob('*.txt'):\n",
        "    with open(file) as file:\n",
        "        print(f\"Opening {file.name}\")\n",
        "        txt = file.readlines()\n",
        "        print(f'Loaded {len(txt)} entries')\n",
        "        for i in range(len(txt)):\n",
        "            txt[i] = clean_text(txt[i])\n",
        "\n",
        "        # Group sentences into chunks of 10\n",
        "        for i in range(0, len(txt), 10):\n",
        "            chunk = \" \".join(txt[i:i+10])\n",
        "            dataset.append(chunk)\n",
        "\n",
        "#print(dataset[:12])\n",
        "#print(len(dataset))\n",
        "#print(dataset)\n"
      ],
      "metadata": {
        "id": "zfWN6dJy1Fnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PDF files"
      ],
      "metadata": {
        "id": "1c8Un0UYRddf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for file in folder.glob('*.pdf'):\n",
        "    doc = fitz.open(file)\n",
        "    full_text = \"\"\n",
        "    for page in doc:\n",
        "        full_text += page.get_text()\n",
        "\n",
        "    full_text_clean = clean_text(full_text)\n",
        "\n",
        "    # Split into sentences\n",
        "    sentences = re.split(r\"(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s\", full_text_clean)\n",
        "\n",
        "    # Group sentences into chunks of 10\n",
        "    for i in range(0, len(sentences), 10):\n",
        "        chunk = \" \".join(sentences[i:i+10])\n",
        "        dataset.append(chunk)\n"
      ],
      "metadata": {
        "id": "4EbJt0Z8RfMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Wikipedia pages"
      ],
      "metadata": {
        "id": "jXdYrU11UkUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wikipedia.set_lang(\"en\")\n",
        "paragraphs = []\n",
        "\n",
        "# Excluded sections\n",
        "excluded = {\"see also\", \"notes\", \"references\", \"sources\"}\n",
        "\n",
        "for title in wikipedia_page_titles :\n",
        "    try :\n",
        "        page = wikipedia.page(title, auto_suggest=False)\n",
        "    except Exception as e:\n",
        "        print(f\"The page {title} doesn't exist, check the title. The process doesn't include it.\")\n",
        "        continue\n",
        "\n",
        "    # Section splitting\n",
        "    sections = re.split(r\"\\n==+ (.*?) ==+\\n\", page.content)\n",
        "\n",
        "    structured_sections = []\n",
        "    for i in range(1, len(sections), 2):\n",
        "        title = sections[i].strip()\n",
        "        content = sections[i+1].strip()\n",
        "\n",
        "        if title.lower() not in excluded and content:\n",
        "            structured_sections.append((title, content))\n",
        "\n",
        "    # Paragraph extraction\n",
        "    for title, content in structured_sections:\n",
        "        for para in content.split(\"\\n\\n\"):\n",
        "            if para:\n",
        "                para = clean_text(para)\n",
        "                paragraphs.append(title + \": \" + para)\n",
        "\n",
        "dataset.extend(paragraphs)"
      ],
      "metadata": {
        "id": "DuAUADz-Uo7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Youtube Videos"
      ],
      "metadata": {
        "id": "oHuSrYTAWAkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_youtube_video(query, max_results=3):\n",
        "    youtube = build('youtube', 'v3', developerKey=YT_API_KEY)\n",
        "    request = youtube.search().list(\n",
        "        q=query,\n",
        "        part=\"id\",\n",
        "        maxResults=max_results,\n",
        "        type=\"video\"\n",
        "    )\n",
        "    response = request.execute()\n",
        "    video_IDs = []\n",
        "    for item in response.get(\"items\", []):\n",
        "        print(item)\n",
        "        if item[\"id\"][\"kind\"] == \"youtube#video\":\n",
        "            video_IDs.append(item[\"id\"][\"videoId\"])\n",
        "    return video_IDs"
      ],
      "metadata": {
        "id": "VXWjE4JBWCjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for title in youtube_video_titles :\n",
        "    video_IDs = search_youtube_video(title)\n",
        "    for video_ID in video_IDs :\n",
        "      yt_api = YouTubeTranscriptApi()\n",
        "      try :\n",
        "        transcript = yt_api.fetch(video_id=video_ID, languages=['en'])\n",
        "      except Exception as e:\n",
        "        print(f\"Subtitles not available\")\n",
        "        continue\n",
        "      string =\"\"\n",
        "      for snippet in transcript:\n",
        "        string += snippet.text + \" \"\n",
        "      sentences = re.split(r\"(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s\", string)\n",
        "      # Group sentences into chunks of 10\n",
        "      for i in range(0, len(sentences), 10):\n",
        "        chunk = \" \".join(sentences[i:i+10])\n",
        "        dataset.append(chunk)\n"
      ],
      "metadata": {
        "id": "34l6O-ulXB_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Manual Processing (Python list and for-loop)"
      ],
      "metadata": {
        "id": "iMA8HNdiUr_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Vector DB"
      ],
      "metadata": {
        "id": "dRkT9BS7UhdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VECTOR_DB = []\n",
        "\n",
        "def add_chunk_to_database(chunk):\n",
        "  embedding = model.encode(chunk)\n",
        "  VECTOR_DB.append((chunk, embedding))"
      ],
      "metadata": {
        "id": "A23PZHvEWpfd",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Distance Functions"
      ],
      "metadata": {
        "id": "1sgXPbBf7slN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Cosine similarity"
      ],
      "metadata": {
        "id": "WMeVOm0Q78HK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(a,b) :\n",
        "  return np.dot(a,b) / (np.linalg.norm(a) * np.linalg.norm(b))"
      ],
      "metadata": {
        "id": "bq5bbuos77f4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Retrieval function"
      ],
      "metadata": {
        "id": "rnPMDuAY8O6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve(query, top_n=3) :\n",
        "  query_embedding = model.encode(query)\n",
        "  similarities = []\n",
        "  for chunk, embedding in VECTOR_DB :\n",
        "    similarity = cosine_similarity(query_embedding, embedding)\n",
        "    similarities.append((chunk,similarity))\n",
        "  similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "  return similarities[:top_n]\n"
      ],
      "metadata": {
        "id": "fyLai6gb8UTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FAISS processing"
      ],
      "metadata": {
        "id": "BOJTn4wyU788"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if MODE == \"FAISS\" :\n",
        "    d = model.get_sentence_embedding_dimension()  #embeddings dimension\n",
        "    index = faiss.IndexFlatIP(d)\n",
        "\n",
        "    VECTOR_DB = []\n",
        "\n",
        "    def add_chunk_to_database(chunk):\n",
        "        embedding = model.encode(chunk)\n",
        "        embedding = embedding / np.linalg.norm(embedding)  # normalization for cosinus\n",
        "        embedding = np.array([embedding]).astype(\"float32\")\n",
        "        index.add(embedding)\n",
        "        VECTOR_DB.append(chunk)\n",
        "\n",
        "    def retrieve(query, top_n=3):\n",
        "        query_embedding = model.encode(query)\n",
        "        query_embedding = query_embedding / np.linalg.norm(query_embedding)\n",
        "        query_embedding = np.array([query_embedding]).astype(\"float32\")\n",
        "\n",
        "        D, I = index.search(query_embedding, top_n)\n",
        "        results = [(VECTOR_DB[idx], float(D[0][j])) for j, idx in enumerate(I[0])]\n",
        "        return results"
      ],
      "metadata": {
        "id": "M9nD7kVTWbXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chunk to database"
      ],
      "metadata": {
        "id": "J928B_qTl8kl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, chunk in enumerate(dataset) :\n",
        "  add_chunk_to_database(chunk)\n",
        "  if (i+1) % 10 == 0:\n",
        "    print(f'Added chunk {i+1}/{len(dataset)} to the database')\n",
        "\n",
        "print(\"All chunks successfully added\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4CJuU7H1XKFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generation"
      ],
      "metadata": {
        "id": "SqDECmPBIFeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_query = input('Ask a question:')\n",
        "retrieved_knowledge = retrieve(input_query,9)\n",
        "print('Retrieved knowledge:')\n",
        "for chunk, similarity in retrieved_knowledge:\n",
        "  print(f' - (similarity: {similarity:.2f}) {chunk}')\n",
        "\n",
        "instruction_prompt = f'''You're a helpful assistant. Use only the following pieces of context to answer the question. Don't make up any new information:\n",
        "{'\\n'.join([f' - {chunk}' for chunk, similarity in retrieved_knowledge])}\n",
        "'''\n",
        "\n",
        "if ai_type == \"gemini\" :\n",
        "    client = genai.Client(api_key=API_KEY)\n",
        "    response = client.models.generate_content_stream(model=ai_model, config=types.GenerateContentConfig(system_instruction=instruction_prompt), contents=input_query)\n",
        "    print(\"\\n\\n\")\n",
        "    for chunk in response:\n",
        "        print(chunk.text, end=\"\")\n",
        "\n",
        "elif ai_type == \"mistral\" :\n",
        "    client = Mistral(api_key=API_KEY)\n",
        "    response = client.chat.stream(model=ai_model,messages = [{\"role\":\"system\",\"content\":instruction_prompt},{\"role\":\"user\",\"content\":input_query}])\n",
        "    print(\"\\n\\n\")\n",
        "    for chunk in response :\n",
        "        print(chunk.data.choices[0].delta.content, end=\"\")\n",
        "\n",
        "elif ai_type == \"groq\" :\n",
        "    client = Groq(api_key=API_KEY)\n",
        "    response = client.chat.completions.create(model=ai_model,messages = [{\"role\":\"system\",\"content\":instruction_prompt},{\"role\":\"user\",\"content\":input_query}],stream=True)\n",
        "    print(\"\\n\\n\")\n",
        "    for chunk in response:\n",
        "        print(chunk.choices[0].delta.content, end=\"\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "36MJCmGFIHMO",
        "outputId": "7e6ba575-b043-4d79-a512-24363b4b20e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ask a question:Which war was the most murderous ?\n",
            "Retrieved knowledge:\n",
            " - (similarity: 0.48) Casualties and war crimes: In Asia and the Pacific, the number of people killed by Japanese troops remains contested. According to R.J. Rummel, the Japanese killed between 3 million and more than 10 million people, with the most probable case of almost 6,000,000 people. According to the British historian M. R. D. Foot, civilian deaths are between 10 million and 20 million, whereas Chinese military casualties (killed and wounded) are estimated to be over five million. Other estimates say that up to 30 million people, most of them civilians, were killed. The most infamous Japanese atrocity was the Nanjing Massacre, in which fifty to three hundred thousand Chinese civilians were raped and murdered. Mitsuyoshi Himeta reported that 2.47 million casualties occurred during the Three Alls policy. General Yasuji Okamura implemented the policy in Hebei and Shandong. Axis forces employed biological and chemical weapons. The Imperial Japanese Army used a variety of such weapons during its invasion and occupation of China (see Unit 731) and in early conflicts against the Soviets. Both the Germans and the Japanese tested such weapons against civilians, and sometimes on prisoners of war. The Soviet Union was responsible for the Katyn massacre of 22,000 Polish officers, and the imprisonment or execution of hundreds of thousands of political prisoners by the NKVD secret police, along with mass civilian deportations to Siberia, in the Baltic states and eastern Poland annexed by the Red Army. Soviet soldiers committed mass rapes in occupied territories, especially in Germany. The exact number of German women and girls raped by Soviet troops during the war and occupation is uncertain, but historians estimate their numbers are likely in the hundreds of thousands, and possibly as many as two million, while figures for women raped by German soldiers in the Soviet Union go as far as ten million. The mass bombing of cities in Europe and Asia has often been called a war crime, although no positive or specific customary international humanitarian law with respect to aerial warfare existed before or during World War II. The USAAF bombed a total of 67 Japanese cities, killing 393,000 civilians, including the atomic bombings of Hiroshima and Nagasaki, and destroying 65% of built-up areas.\n",
            " - (similarity: 0.43) Further reading: Buchanan, Andrew (7 February 2023). \"Globalizing the Second World War\". Past & Present (258): 246–281. doi:10.1093/pastj/gtab042. ISSN 0031-2746. also see online review Archived 4 May 2024 at the Wayback Machine Gerlach, Christian (2024). Conditions of Violence. Walter de Gruyter GmbH & Co KG. ISBN 978-3-1115-6873-7.\n",
            " - (similarity: 0.43) Casualties: The total number of military and civilian casualties in World War I was about 40 million: estimates range from around 15 to 22 million deaths and about 23 million wounded military personnel, ranking it among the deadliest conflicts in human history. The total number of deaths includes between 9 and 11 million military personnel, with an estimated civilian death toll of about 6 to 13 million. Of the 60 million European military personnel who were mobilised from 1914 to 1918, an estimated 8 million were killed, 7 million were permanently disabled, and 15 million were seriously injured. Germany lost 15.1% of its active male population, Austria-Hungary lost 17.1%, and France lost 10.5%. France mobilised 7.8 million men, of which 1.4 million died and 3.2 million were injured. Approximately 15,000 deployed men sustained gruesome facial injuries, causing social stigma and marginalisation; they were called the gueules cassées (broken faces). In Germany, civilian deaths were 474,000 higher than in peacetime, due in large part to food shortages and malnutrition that had weakened disease resistance. These excess deaths are estimated as 271,000 in 1918, plus another 71,000 in the first half of 1919 when the blockade was still in effect. Starvation caused by famine killed approximately 100,000 people in Lebanon.\n",
            " - (similarity: 0.43) Chemical weapons in warfare: The German army was the first to successfully deploy chemical weapons during the Second Battle of Ypres (April–May 1915), after German scientists under the direction of Fritz Haber at the Kaiser Wilhelm Institute developed a method to weaponise chlorine. The use of chemical weapons had been sanctioned by the German High Command to force Allied soldiers out of their entrenched positions, complementing rather than supplanting more lethal conventional weapons. Chemical weapons were deployed by all major belligerents throughout the war, inflicting approximately 1.3 million casualties, of which about 90,000 were fatal. The use of chemical weapons in warfare was a direct violation of the 1899 Hague Declaration Concerning Asphyxiating Gases and the 1907 Hague Convention on Land Warfare, which prohibited their use.\n",
            " - (similarity: 0.41) Casualties and war crimes: Estimates for the total number of casualties in the war vary, because many deaths went unrecorded. Most suggest 60 million people died, about 20 million military personnel and 40 million civilians. The Soviet Union alone lost around 27 million people during the war, including 8.7 million military and 19 million civilian deaths. A quarter of the total people in the Soviet Union were wounded or killed. Germany sustained 5.3 million military losses, mostly on the Eastern Front and during the final battles in Germany. An estimated 11 to 17 million civilians died as a direct or as an indirect result of Hitler's racist policies, including mass killing of around 6 million Jews, along with Roma, homosexuals, at least 1.9 million ethnic Poles and millions of other Slavs (including Russians, Ukrainians and Belarusians), and other ethnic and minority groups. Between 1941 and 1945, more than 200,000 ethnic Serbs, along with Roma and Jews, were persecuted and murdered by the Axis-aligned Croatian Ustaše in Yugoslavia. Concurrently, Muslims and Croats were persecuted and killed by Serb nationalist Chetniks, with an estimated 50,000–68,000 victims (of which 41,000 were civilians). Also, more than 100,000 Poles were massacred by the Ukrainian Insurgent Army in the Volhynia massacres, between 1943 and 1945. At the same time, about 10,000–15,000 Ukrainians were killed by the Polish Home Army and other Polish units, in reprisal attacks.\n",
            " - (similarity: 0.40) Genocide, concentration camps, and slave labour: Nazi Germany, under the dictatorship of Adolf Hitler, was responsible for murdering about 6 million Jews in what is now known as the Holocaust. They also murdered an additional 4 million others who were deemed \"unworthy of life\" (including the disabled and mentally ill, Soviet prisoners of war, Romani, homosexuals, Freemasons, and Jehovah's Witnesses) as part of a program of deliberate extermination, in effect becoming a \"genocidal state\". Soviet POWs were kept in especially unbearable conditions, and 3.6 million Soviet POWs out of 5.7 million died in Nazi camps during the war. In addition to concentration camps, death camps were created in Nazi Germany to exterminate people on an industrial scale. Nazi Germany extensively used forced labourers; about 12 million Europeans from German-occupied countries were abducted and used as a slave work force in German industry, agriculture and war economy.\n",
            " - (similarity: 0.39) Historiography: The first efforts to comprehend the meaning and consequences of modern warfare began during the initial phases of the war and are still underway more than a century later. Teaching World War I has presented special challenges. When compared with World War II, the First World War is often thought to be \"a wrong war fought for the wrong reasons\"; it lacks the metanarrative of good versus evil that characterises retellings of the Second World War. Lacking recognizable heroes and villains, it is often taught thematically, invoking simplified tropes that obscure the complexity of the conflict. Historian Heather Jones argues that the historiography has been reinvigorated by a cultural turn in the 21st century. Scholars have raised entirely new questions regarding military occupation, radicalisation of politics, race, medical science, gender and mental health. Among the major subjects that historians have long debated regarding the war include why the war began, why the Allies won, whether generals were responsible for high casualty rates, how soldiers endured the poor conditions of trench warfare, and to what extent the civilian home front accepted and endorsed the war effort.\n",
            " - (similarity: 0.37) Aftermath: In the aftermath of the war, the German, Austro-Hungarian, Ottoman, and Russian empires disappeared. Numerous nations regained their former independence, and new ones were created. Four dynasties fell as a result of the war: the Romanovs, the Hohenzollerns, the Habsburgs, and the Ottomans. Belgium and Serbia were badly damaged, as was France, with 1.4 million soldiers dead, not counting other casualties. Germany and Russia were similarly affected.\n",
            " - (similarity: 0.37) Formal end of the war: Germany on 10 January 1920. Austria on 16 July 1920. Bulgaria on 9 August 1920. Hungary on 26 July 1921. Turkey on 6 August 1924.\n",
            "\n",
            "\n",
            "\n",
            "According to the provided context, World War II was the most murderous, with estimates suggesting around 60 million people died, including 20 million military personnel and 40 million civilians. This is compared to World War I, which had around 40 million casualties, including 15-22 million deaths and 23 million wounded military personnel.None"
          ]
        }
      ]
    }
  ]
}